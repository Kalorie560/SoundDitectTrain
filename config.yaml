# SoundDitect Configuration File
# Real-time Sound Anomaly Detection System

# Project Information
project:
  name: "SoundDitect"
  version: "1.0.0"
  description: "Real-time Sound Anomaly Detection AI Application"

# ClearML Configuration
clearml:
  project_name: "SoundDitect"
  task_name: "anomaly_detection_training"
  output_uri: "file://./outputs"

# Audio Processing Configuration
audio:
  sample_rate: 44100  # Hz - audio sampling rate
  channels: 1         # Mono audio
  format: "float32"
  chunk_size: 4096    # Audio chunk size for processing

# Model Configuration
model:
  architecture: "1d_cnn_attention"  # 1D-CNN with attention mechanism
  input_length: 44100  # 1 second of audio at 44.1kHz
  num_classes: 2       # Normal (0) vs Anomaly (1)
  
  # Model Architecture Parameters - Hierarchical kernel sizes for strike sound detection
  cnn_layers:
    # First layer: Large kernel to capture resonance and low-frequency components
    - filters: 64
      kernel_size: 255  # ~5.8ms range for sound resonance
      stride: 1
      padding: "same"
    # Second layer: Medium kernel to refine features
    - filters: 128
      kernel_size: 63   # Medium range for feature refinement
      stride: 1
      padding: "same"
    # Third layer: Small kernel to capture sharp attack features
    - filters: 128
      kernel_size: 31   # Sharp attack and fine detail features
      stride: 1
      padding: "same"
  
  attention:
    hidden_dim: 128
    num_heads: 4
  
  fully_connected:
    - units: 256
      dropout: 0.3
    - units: 128
      dropout: 0.3

# Training Configuration - Optimized with improved learning strategies
training:
  batch_size: 4  # Reduced for large kernel compatibility
  epochs: 50     # Reduced for efficient training with scheduler
  learning_rate: 0.001
  optimizer: "adam"
  
  # Learning rate scheduler for stable convergence
  lr_scheduler:
    name: "CosineAnnealingLR"  # Automatic learning rate adjustment
    T_max: 50                  # Maximum epochs
    eta_min: 0.00001           # Minimum learning rate
  
  # Improved loss function for imbalanced data
  loss_function:
    name: "binary_crossentropy"
    # Weight for positive class (strike sounds) - adjust based on data ratio
    # If normal sounds are 5x more common than strikes, use pos_weight: 5.0
    pos_weight: 5.0
  
  validation_split: 0.2
  early_stopping:
    patience: 10  # Efficient early stopping
    monitor: "val_loss"
  
  # Data augmentation
  augmentation:
    noise_factor: 0.01
    time_shift_max: 0.1
    pitch_shift_range: [-2, 2]

# Data Processing Configuration
data:
  data_dir: "./data"
  output_dir: "./outputs"
  model_save_path: "./models"
  
  # Memory efficiency settings - Optimized for Colab T4
  use_data_generator: true
  max_memory_usage: "8GB"  # Reduced for Colab compatibility
  prefetch_buffer_size: 1  # Reduced for memory efficiency
  
  # Memory management settings - GPU optimized
  gradient_accumulation_steps: 4  # Reduced for faster updates
  memory_efficient_attention: true
  pin_memory: false  # Keep false for Colab stability

# Colab-specific optimizations (automatically detected)
colab:
  enable_gradient_checkpointing: true  # Save memory during backprop
  mixed_precision: true               # Enable automatic mixed precision
  cache_size_limit: 50               # Limit cached samples for memory efficiency
  aggressive_memory_cleanup: true     # Enable aggressive memory cleanup
  monitor_memory_every_n_batches: 5   # Monitor memory more frequently

# Data Configuration - Multiple JSON File Support
# The system will automatically find and integrate ALL *.json files in the data directory
# This allows you to use multiple JSON files as training resources instead of combining them manually
# 
# Supported formats:
# - New format: {"waveforms": [[...]], "labels": ["OK", "NG"], "fs": 44100}
# - Old format: [{"Waveform": [...], "Labels": 0}, {"Waveform": [...], "Labels": 1}]
# 
# Multiple file handling:
# - Single file: Used for both training and validation
# - Multiple files: Automatically split between training and validation based on validation_split ratio


# Preprocessing Configuration
preprocessing:
  normalize: true
  apply_filter: true
  filter_type: "butterworth"
  filter_params:
    low_freq: 20    # Hz
    high_freq: 8000 # Hz
    order: 4

# Inference Configuration
inference:
  confidence_threshold: 0.5
  model_path: "./models/best_model.pth"
  use_gpu: true  # Enable GPU when available (automatically uses CPU as fallback)
  
# Logging Configuration
logging:
  level: "INFO"
  file: "./logs/soundditect.log"
  max_file_size: "10MB"
  backup_count: 5