# SoundDitect Configuration File
# Real-time Sound Anomaly Detection System

# Project Information
project:
  name: "SoundDitect"
  version: "1.0.0"
  description: "Real-time Sound Anomaly Detection AI Application"

# ClearML Configuration
clearml:
  project_name: "SoundDitect"
  task_name: "anomaly_detection_training"
  output_uri: "file://./outputs"

# Audio Processing Configuration
audio:
  sample_rate: 44100  # Hz - audio sampling rate
  channels: 1         # Mono audio
  format: "float32"
  chunk_size: 4096    # Audio chunk size for processing

# Model Configuration
model:
  architecture: "1d_cnn_attention"  # 1D-CNN with attention mechanism
  input_length: 44100  # 1 second of audio at 44.1kHz
  num_classes: 2       # Normal (0) vs Anomaly (1)
  
  # Model Architecture Parameters
  cnn_layers:
    - filters: 64
      kernel_size: 63
      stride: 1
      padding: "same"
    - filters: 128
      kernel_size: 31
      stride: 1
      padding: "same"
    - filters: 128
      kernel_size: 31
      stride: 1
      padding: "same"
  
  attention:
    hidden_dim: 128
    num_heads: 4
  
  fully_connected:
    - units: 256
      dropout: 0.3
    - units: 128
      dropout: 0.3

# Training Configuration
training:
  batch_size: 8
  epochs: 100
  learning_rate: 0.001
  optimizer: "adam"
  loss_function: "binary_crossentropy"
  validation_split: 0.2
  early_stopping:
    patience: 10
    monitor: "val_loss"
  
  # Data augmentation
  augmentation:
    noise_factor: 0.01
    time_shift_max: 0.1
    pitch_shift_range: [-2, 2]

# Data Processing Configuration
data:
  data_dir: "./data"
  output_dir: "./outputs"
  model_save_path: "./models"
  
  # Memory efficiency settings
  use_data_generator: true
  max_memory_usage: "10GB"
  prefetch_buffer_size: 2
  
  # Memory management settings
  gradient_accumulation_steps: 8
  memory_efficient_attention: true
  pin_memory: false

# Data Configuration - Multiple JSON File Support
# The system will automatically find and integrate ALL *.json files in the data directory
# This allows you to use multiple JSON files as training resources instead of combining them manually
# 
# Supported formats:
# - New format: {"waveforms": [[...]], "labels": ["OK", "NG"], "fs": 44100}
# - Old format: [{"Waveform": [...], "Labels": 0}, {"Waveform": [...], "Labels": 1}]
# 
# Multiple file handling:
# - Single file: Used for both training and validation
# - Multiple files: Automatically split between training and validation based on validation_split ratio


# Preprocessing Configuration
preprocessing:
  normalize: true
  apply_filter: true
  filter_type: "butterworth"
  filter_params:
    low_freq: 20    # Hz
    high_freq: 8000 # Hz
    order: 4

# Inference Configuration
inference:
  confidence_threshold: 0.5
  model_path: "./models/best_model.pth"
  use_gpu: false  # Set to true if CUDA available
  
# Logging Configuration
logging:
  level: "INFO"
  file: "./logs/soundditect.log"
  max_file_size: "10MB"
  backup_count: 5